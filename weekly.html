<!DOCTYPE html>

<html>
  <body bgcolor="E9ECF5">
    <div class="header">
      <h1 align="center">Blake Ehrenbek</h1>
    </div>

    <div class="menu">
      <span align="center" class="linkspan">
        <a href="index.html" class="menulink">About</a>
        <a href="info.html" class="menulink">Project Info</a>
        <a href="weekly.html" class="menulink selectedlink">Weekly Updates</a>
        <a href="contact.html" class="menulink">Contact</a>
      </span>
    </div>

    <div class="content">
      <h3>Week 1</h3>
      <p>I was tasked with reading the following papers:</p>

      <ul style="line-height:1.4;">
        <li><i>Planning Considerations for Job Scheduling in HPC Clusters</i> by Saeed Iqbal, Rinku Gupta, and Yung-Chin Fang.</li>
        <li><i>Utilization, Predictability, Workloads, and User Runtime Estimates in Scheduling the IBM SP2 with Backfilling</i>
        by Ahuva W. Mu'alem and Dror G. Feitelson</li>
        <li><i>Analysis of the Tradeoffs between Energy and Run Time for Multilevel Checkpointing</i> by
          Prasanna Balaprakash, Leonardo A. Bautista Gomez, Mohamed-Slim Bouguerra, Stefan M. Wild,
          Franck Cappello, and Paul D. Hovland
        </li>
        <li><i>Evaluating Energy and Power Impacts of Multilevel Checkpointing MPI Applications on Three Parallel Architectures: An Empirical Case Study</i> by
        Xingfu Wu, Valerie Taylor, and Zhiling Lan</li>
      </ul>

      <p>The first paper I read was <i>Planning Considerations for Job Scheduling in HPC Clusters</i>. <a href="ConsiderationsNotes.pdf">(My Notes)</a></p>
      <p>Some of the terminology from this paper such as <b>throughput</b> and <b>utilization</b> were familiar to me
      from taking CS351. I was not familiar with some other terms in the paper such as <b>load balancing</b> and <b>round robin scheduling</b>. So
    to better my understanding I read more information about <a href="http://www.personal.kent.edu/~rmuhamma/OpSystems/Myos/roundRobinSchedule.htm">round robin scheduling
    </a> and read a quick definition defining load balancing. This paper provided me with the basics of scheduling in cluster computing.</p>

    <p>Second, I read <i>Utilization, Predictability, Workloads, and User Runtime Estimates in Scheduling the IBM SP2 with Backfilling</i>. <a href="estimatenotes.pdf">(My Notes)</a></p>
    <p>This paper began by detailing two backfilling algorithms: <b>EASY</b> and <b>Conservative Backfilling</b>. It concluded by
    discussing and comparing data from two simulations with one run using EASY backfilling and the other conservative backfilling. It also looked specifically at user
  estimate runtimes and their effect on performance. Something that stood out to me in this work
was the revelation that better user runtime estimates do not necessarily produce better outcomes.</p>

<p>Next, I read <i>Analysis of the Tradeoffs between Energy and Run Time for Multilevel Checkpointing</i>.
  <a href="multilevelnotes.pdf">(My Notes)</a>
</p>
<p>The concept of <b>bi-objective optimzation</b> was brought up in this paper several times as were the terms
  <b>pareto optimal</b> and <b>pareto fronts</b>. This was my first introduction to these concepts. I understood these as described by the paper.</p>

<p>Lastly I read <i>Evaluating Energy and Power Impacts of Multilevel Checkpointing MPI Applications on Three Parallel Architectures: An Empirical Case Study</i>.<a href="empnotes.pdf">(My Notes)</a><p>
  <p>I was unfamiliar with <b>MPI</b> or <b>Message Passing Interface</b> so I did some supplemental reading to get an idea about what this was.</p>

<p>For now, I have no additional questions about these papers, but as I work more with these concepts I expect some to arise.</p>

  <h3>Week 2</h3>
  <p>I was given some more papers to read on. Some on MUMMI modeling and others on the tools used to collect data.</p>
  <p>I was given some data from a program, CG, that was run on Mira. My task was to upload this data to the MUMMI database.
  A tool maide was designed for recording data during a program run and uploading said data to the database. The data that I had was broken into two pieces:
PAPI data and MonEQ data. So, I used a script in maide to convert the MonEQ data into a power.txt file. Then I manually created a *.p000 file.
This file incorporated data from the PAPI file as well as the power.txt file. Once I had created all the *.p000 files, I attempted to
upload them to the database with a pearl script included in maide. I was given an error: "Server says: Error opening file". As of now, I'm not sure
why I am getting this error. I will contact Professor Wu to see if he may know why I cannot upload the files.</p>

<h3>Week 3</h3>
<p>I read several more papers. Some dealing with fault prediction and one on anomoly detection as well as scheduling policy. I took more notes on these papers. My main focus this week was to finish
uploading the data from CG being run on ANL Mira to the MuMMI database. As mentioned in the previous week's report, I had an error
uploading the data to MuMMI. I was able to resolve this problem and successfuly uploaded the data
to the MuMMI database. When I originally created the files to be uploaded to the database, I mistakenly
created a separate file for each node card number and erroneously equated node card number to to processor number. I noticed this mistake when I saw
two defined patterns in the plots of power consumption whereas other examples I looked at had only one.

 As it turns out,
I only needed to create a file the first node card as the data from the other node cards is irrelevant. </p>

<h3>Week 4</h3>
<p>I continued to read papers on the data analytics side of fault prediction and anomoly prediction. This was my first exposure to many data analytics techniques.
I reread some of the papers I read in Week 3 as I was still a little unsure of the content. I took extensive notes
to help me understand what I had read. I met with Professor Lan to discuss the possibility of continuing to work on the project throughout part of the upcoming semester.
</p>

<h3>Fall Project</h3>
<h4>Summary</h4>
<p>
  For the Fall Project I was to take four programs run on ANL Mira and upload power information about them to
  the MUMMI_R database. The four programs were: cg, ft, lu, and stream. Unlike the previous project I was not given PAPI data for the runs. In the previous project I had already uploaded data about cg,
  so I was familiar with the parameters it was run under. For ft, and lu, I needed information
  about the ClassE input size and the number of iterations it was run. I was able to find this information
  inside the log from the ANL Mira run. cg, ft, and lu all had a ClassE input size. When I tried to find the ClassE input size for Stream,
  my search was unsuccesful. After an email exchange with Yuping Fan, who had originally run these programs on ANL mira, I learned
  that there was no ClassE input size for Stream. As it turns out, Stream is a benchmark that measures memory bandwith. Furthermore when I needed to
  include the number of iterations as input, I was unable to do so because Stream does not define the number of iterations.
  In order to upload the data to the database, I needed to create p000 files with information that detailed the run on ANL Mira. I then used a script to upload the p000 file to the databse.
</p>
<h4>Converting the MonEQ Data</h4>
<p>For the power information to be uploaded to the database, it needed to be in a different format
than the MonEQ output given to me. I used a script included in Maide to convert it to a suitable format
to be included in the p000 file.</p>
<p>The next section details the layout of the p000 files that I created.</p>
<h4>Layout of the p000 File</h4>
<p>
The first section of the p000 file is reserved for metadata about the run and some information about the program.
</p>
<p>
  <ul style="list-style-type:circle">
  <li>Run Date: The Date of the ANL Mira run. I found this information in the MonEQ outut file.</li>
  <li>Executable Name: The name of the executable run on ANL Mira. For example cg runnning on 1024 cores was cg-1024-classE</li>
  <li>Runtime: The total runtime of the program [From converted MonEQ file]</li>
  <li>Start Timestamp: The start timestamp [From converted MonEQ file]</li>
  <li>End Timestamp: The end timestamp [From converted MonEQ file]</li>
  <li>Number of Processors: Number of processors the program was run on </li>
  <li>Number of MPI: Number of MPI threads. (See <a href="https://computing.llnl.gov/tutorials/mpi/">MPI</a> to learn about MPI)</li>
  <li>Number of Threads: 1</li>
  <li>Total cores per node: 4</li>
  <li>Core speed: 1.600000 GHz</li>
  <li>Owner Name: Name used to register program </li>
  <li>Email: email used to register program </li>
  <li>Application Name: The name of the application. {cg,lu,ft,stream}</li>
  <li>Version: [From output log from run]</li>
  <li>System name: ANL Mira</li>
  </ul>
  <p>The next section includes input information. Here I added the ClassE input size for cg, lu, and ft. (Stream, as I mentioned above had no ClassE input size.)
  Also in this section, if the program was run with FTI, the checkpoints are specified.
  </p>
  <p>
    The final section is just the converted MonEQ file copied over to the p000 file.
  </p>

</p>

    </div>



  </body>
  <head>
    <link rel="stylesheet" type="text/css" href="style.css">
  </head>
</html>
